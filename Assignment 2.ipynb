{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "92778525",
   "metadata": {},
   "source": [
    "# Assignment 2: Linear Models and Validation Metrics (30 marks total)\n",
    "### Due: October 10 at 11:59pm\n",
    "\n",
    "### Name: "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce31b39a",
   "metadata": {},
   "source": [
    "### In this assignment, you will need to write code that uses linear models to perform classification and regression tasks. You will also be asked to describe the process by which you came up with the code. More details can be found below. Please cite any websites or AI tools that you used to help you with this assignment."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7c6de86",
   "metadata": {},
   "source": [
    "## Part 1: Classification (14.5 marks total)\n",
    "\n",
    "You have been asked to develop code that can help the user determine if the email they have received is spam or not. Following the machine learning workflow described in class, write the relevant code in each of the steps below:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e3c6fc8",
   "metadata": {},
   "source": [
    "### Step 0: Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 324,
   "id": "33f86925",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import yellowbrick\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f9d33a8",
   "metadata": {},
   "source": [
    "### Step 1: Data Input (1 mark)\n",
    "\n",
    "The data used for this task can be downloaded using the yellowbrick library: \n",
    "https://www.scikit-yb.org/en/latest/api/datasets/spam.html\n",
    "\n",
    "Use the yellowbrick function `load_spam()` to load the spam dataset into the feature matrix `X` and target vector `y`.\n",
    "\n",
    "Print the size and type of `X` and `y`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 325,
   "id": "33583c67",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Size of X is: 262200, Type of X is: <class 'pandas.core.frame.DataFrame'>\n",
      "Size of y is: 4600, Type of y is: <class 'pandas.core.series.Series'>\n"
     ]
    }
   ],
   "source": [
    "# TO DO: Import spam dataset from yellowbrick library\n",
    "# TO DO: Print size and type of X and y\n",
    "X, y = yellowbrick.datasets.loaders.load_spam(data_home=None, return_dataset=False)\n",
    "print(f\"Size of X is: {X.size}, Type of X is: {type(X)}\")\n",
    "print(f\"Size of y is: {y.size}, Type of y is: {type(y)}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "156db208",
   "metadata": {},
   "source": [
    "### Step 2: Data Processing (1.5 marks)\n",
    "\n",
    "Check to see if there are any missing values in the dataset. If necessary, select an appropriate method to fill-in the missing values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 326,
   "id": "4e7204f5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 0 missing values in the dataset\n"
     ]
    }
   ],
   "source": [
    "# TO DO: Check if there are any missing values and fill them in if necessary\n",
    "missing_value = X.isnull().sum().sum()+y.isnull().sum()\n",
    "print(f\"There are {missing_value} missing values in the dataset\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a489285a",
   "metadata": {},
   "source": [
    "For this task, we want to test if the linear model would still work if we used less data. Use the `train_test_split` function from sklearn to create a new feature matrix named `X_small` and a new target vector named `y_small` that contain **5%** of the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 327,
   "id": "f9bc4a23",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TO DO: Create X_small and y_small \n",
    "from sklearn.model_selection import train_test_split\n",
    "_, X_small, _, y_small = train_test_split(X, y, test_size=0.05, random_state= 0)\n",
    "# print(X_small_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70e6c46f",
   "metadata": {},
   "source": [
    "### Step 3: Implement Machine Learning Model\n",
    "\n",
    "1. Import `LogisticRegression` from sklearn\n",
    "2. Instantiate model `LogisticRegression(max_iter=2000)`.\n",
    "3. Implement the machine learning model with three different datasets: \n",
    "    - `X` and `y`\n",
    "    - Only first two columns of `X` and `y`\n",
    "    - `X_small` and `y_small`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 328,
   "id": "5415bae7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "model = LogisticRegression(max_iter=2000)\n",
    "#Train_test_split and fit with training data\n",
    "#First machine learning model\n",
    "X_train,X_val,y_train,y_val = train_test_split(X,y, random_state= 0)\n",
    "model1 = model.fit(X_train, y_train)\n",
    "\n",
    "#Second machine learning model\n",
    "X_col = X.iloc[:,:2]\n",
    "X_col_train, X_col_val, y_train, y_val = train_test_split(X_col, y, random_state= 0)\n",
    "model2 = model.fit(X_col_train, y_train)\n",
    "\n",
    "#Third machine learning model\n",
    "X_small_train, X_small_val, y_small_train, y_small_val = train_test_split(X_small, y_small, random_state= 0)\n",
    "model3 = model.fit(X_small_train, y_small_train)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b89f3d84",
   "metadata": {},
   "source": [
    "### Step 4: Validate Model\n",
    "\n",
    "Calculate the training and validation accuracy for the three different tests implemented in Step 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 329,
   "id": "c994de2f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model 1 Training set score: 0.93\n",
      "Model 1 Validation set score: 0.94\n",
      "Model 2 Training set score: 0.61\n",
      "Model 2 Validation set score: 0.61\n",
      "Model 3 Training set score: 0.97\n",
      "Model 3 Validation set score: 0.79\n"
     ]
    }
   ],
   "source": [
    "X_train,X_val,y_train,y_val = train_test_split(X,y, random_state= 0)\n",
    "model1 = model.fit(X_train, y_train)\n",
    "model1_train_score = model1.score(X_train, y_train)\n",
    "model1_test_score = model1.score(X_val, y_val)\n",
    "\n",
    "print(\"Model 1 Training set score: {:.2f}\".format(model1.score(X_train, y_train)))\n",
    "print(\"Model 1 Validation set score: {:.2f}\".format(model1.score(X_val, y_val)))\n",
    "\n",
    "X_col = X.iloc[:,:2]\n",
    "X_col_train, X_col_val, y_train, y_val = train_test_split(X_col, y, random_state= 0)\n",
    "model2 = model.fit(X_col_train, y_train)\n",
    "model2_train_score = model2.score(X_col_train, y_train)\n",
    "model2_test_score = model2.score(X_col_val, y_val)\n",
    "\n",
    "print(\"Model 2 Training set score: {:.2f}\".format(model2.score(X_col_train, y_train)))\n",
    "print(\"Model 2 Validation set score: {:.2f}\".format(model.score(X_col_val, y_val)))\n",
    "\n",
    "X_small_train, X_small_val, y_small_train, y_small_val = train_test_split(X_small, y_small, random_state= 0)\n",
    "model3 = model.fit(X_small_train, y_small_train)\n",
    "model3_train_score = model3.score(X_small_train, y_small_train)\n",
    "model3_test_score = model3.score(X_small_val, y_small_val)\n",
    "\n",
    "print(\"Model 3 Training set score: {:.2f}\".format(model.score(X_small_train, y_small_train)))\n",
    "print(\"Model 3 Validation set score: {:.2f}\".format(model.score(X_small_val, y_small_val)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "352106a3",
   "metadata": {},
   "source": [
    "### Step 5: Visualize Results (4 marks)\n",
    "\n",
    "1. Create a pandas DataFrame `results` with columns: Data size, training accuracy, validation accuracy\n",
    "2. Add the data size, training and validation accuracy for each dataset to the `results` DataFrame\n",
    "3. Print `results`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 330,
   "id": "be4b5c0a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                    Data Size  Training Accuracy  Validation Accuracy\n",
      "Full DataSet       (4600, 57)           0.928696             0.936522\n",
      "First two columns   (4600, 2)           0.608406             0.613043\n",
      "Smaller Dataset     (230, 57)           0.965116             0.793103\n"
     ]
    }
   ],
   "source": [
    "# TO DO: ADD YOUR CODE HERE FOR STEPS 3-5\n",
    "# Note: for any random state parameters, you can use random_state = 0\n",
    "# HINT: USING A LOOP TO STORE THE DATA IN YOUR RESULTS DATAFRAME WILL BE MORE EFFICIENT\n",
    "\n",
    "results = pd.DataFrame(columns = ['Data Size','Training Accuracy','Validation Accuracy'])\n",
    "results.loc[0] = [X.shape, model1_train_score, model1_test_score]\n",
    "results.loc[1] = [X_col.shape, model2_train_score, model2_test_score]\n",
    "results.loc[2] = [X_small.shape, model3_train_score, model3_test_score]\n",
    "results.index = ['Full DataSet', 'First two columns', 'Smaller Dataset']\n",
    "\n",
    "print(results)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4427d4f",
   "metadata": {},
   "source": [
    "### Questions (4 marks)\n",
    "1. How do the training and validation accuracy change depending on the amount of data used? Explain with values.\n",
    "2. In this case, what do a false positive and a false negative represent? Which one is worse?\n",
    "\n",
    "*YOUR ANSWERS HERE*\n",
    "1. When we have the full dataset available, we can see that the training score and accuracy score are both pretty high and close to each other, with the a difference of less than 1%. \n",
    "When we only use the first two columns, our training score drops significantly versus the full dataset. This means using two features is not enough information for our model to make accurate predictions.\n",
    "And the last scenario with a much smaller dataset shows a good score, but the validation score is much lower meaning our model is overfitting.\n",
    "2. In this case, for the spam dataset, a false positive would be when the model incorrectly identifies a regular email as a spam email. Which would place an important email in the spam folder.\n",
    "On the other hand, a false negative would be the model incorrectly identifying spam mail as a regular email. \n",
    "Both scenarios are bad. But a worst scenario would depend on the user. For example, somebody that is more digitally aware would not want a false positive since they are probably better at identifying if there is spam mail in their normal inbox. So they wouldn't want to miss any important emails going to their spam inbox."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7559517a",
   "metadata": {},
   "source": [
    "### Process Description (4 marks)\n",
    "Please describe the process you used to create your code. Cite any websites or generative AI tools used. You can use the following questions as guidance:\n",
    "1. Where did you source your code?\n",
    "1. In what order did you complete the steps?\n",
    "1. If you used generative AI, what prompts did you use? Did you need to modify the code at all? Why or why not?\n",
    "1. Did you have any challenges? If yes, what were they? If not, what helped you to be successful?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59fe687f",
   "metadata": {},
   "source": [
    "*DESCRIBE YOUR PROCESS HERE*\n",
    "\n",
    "For this assignment, I followed all the parts in order beginning with Step 1.  I referred back to the Python examples provided from class and the lab to help with the specifics of using train_test_split as well as fitting the model with X,y data. \n",
    "\n",
    "I did use generative ai for this example. I used ChatGPT to help me get a better understanding of true and false positives/negatives. I simply asked chat \"Can you give an indepth explanation on how true positive, true negative, false positive, and false negative works in data modeling and machine learning\". So I did not need to modify any code as I used ChatGPT to help with understanding my results better.\n",
    "\n",
    "I had challenges in steps 4-5 with getting the code to work in VSCode. For some reason I have to re-call my variables model 1-3 in Step 4 even though it was already done in Step 3. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb4c78a8",
   "metadata": {},
   "source": [
    "## Part 2: Regression (10.5 marks total)\n",
    "\n",
    "For this section, we will be evaluating concrete compressive strength of different concrete samples, based on age and ingredients. You will need to repeat the steps 1-4 from Part 1 for this analysis."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2ba83c5",
   "metadata": {},
   "source": [
    "### Step 1: Data Input (1 mark)\n",
    "\n",
    "The data used for this task can be downloaded using the yellowbrick library: \n",
    "https://www.scikit-yb.org/en/latest/api/datasets/concrete.html\n",
    "\n",
    "Use the yellowbrick function `load_concrete()` to load the spam dataset into the feature matrix `X` and target vector `y`.\n",
    "\n",
    "Print the size and type of `X` and `y`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 331,
   "id": "6ff2e34f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Size of X is: 8240, Type of X is: <class 'pandas.core.frame.DataFrame'>\n",
      "Size of y is: 1030, Type of y is: <class 'pandas.core.series.Series'>\n"
     ]
    }
   ],
   "source": [
    "# TO DO: Import spam dataset from yellowbrick library\n",
    "# TO DO: Print size and type of X and y\n",
    "X, y = yellowbrick.datasets.loaders.load_concrete(data_home=None, return_dataset=False)\n",
    "print(f\"Size of X is: {X.size}, Type of X is: {type(X)}\")\n",
    "print(f\"Size of y is: {y.size}, Type of y is: {type(y)}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5294cfa",
   "metadata": {},
   "source": [
    "### Step 2: Data Processing (0.5 marks)\n",
    "\n",
    "Check to see if there are any missing values in the dataset. If necessary, select an appropriate method to fill-in the missing values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 332,
   "id": "693c5fa3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 0 missing values in the dataset\n"
     ]
    }
   ],
   "source": [
    "# TO DO: Check if there are any missing values and fill them in if necessary\n",
    "missing_value = (X.isnull().sum().sum())+(y.isnull().sum())\n",
    "print(f\"There are {missing_value} missing values in the dataset\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1bc60489",
   "metadata": {},
   "source": [
    "### Step 3: Implement Machine Learning Model (1 mark)\n",
    "\n",
    "1. Import `LinearRegression` from sklearn\n",
    "2. Instantiate model `LinearRegression()`.\n",
    "3. Implement the machine learning model with `X` and `y`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 333,
   "id": "b5041945",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TO DO: ADD YOUR CODE HERE\n",
    "# Note: for any random state parameters, you can use random_state = 0\n",
    "from sklearn.linear_model import LinearRegression\n",
    "X_train, X_val, y_train, y_val = train_test_split(X, y, random_state= 0)\n",
    "lr = LinearRegression().fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1de28482",
   "metadata": {},
   "source": [
    "### Step 4: Validate Model (1 mark)\n",
    "\n",
    "Calculate the training and validation accuracy using mean squared error and R2 score."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 334,
   "id": "970c038b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TO DO: ADD YOUR CODE HERE\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "\n",
    "y_train_pred = lr.predict(X_train)\n",
    "y_val_pred = lr.predict(X_val)\n",
    "\n",
    "#Mean squared error\n",
    "mse_train = mean_squared_error(y_train, y_train_pred)\n",
    "mse_val = mean_squared_error(y_val_pred,y_val)\n",
    "\n",
    "#R2_score\n",
    "r2_train = r2_score(y_train, y_train_pred)\n",
    "r2_val = r2_score(y_val, y_val_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54aa7795",
   "metadata": {},
   "source": [
    "### Step 5: Visualize Results (1 mark)\n",
    "1. Create a pandas DataFrame `results` with columns: Training accuracy and Validation accuracy, and index: MSE and R2 score\n",
    "2. Add the accuracy results to the `results` DataFrame\n",
    "3. Print `results`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 335,
   "id": "88d223f3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     Training accuracy  Validation accuracy\n",
      "MSE         111.358439            95.904136\n",
      "R2            0.610823             0.623414\n"
     ]
    }
   ],
   "source": [
    "# TO DO: ADD YOUR CODE HERE\n",
    "results = pd.DataFrame(columns= [\"Training accuracy\", \"Validation accuracy\"])\n",
    "results.loc[0] = mse_train, mse_val\n",
    "results.loc[1] = r2_train, r2_val\n",
    "results.index = ['MSE', 'R2']\n",
    "print(results)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70a42bda",
   "metadata": {},
   "source": [
    "### Questions (2 marks)\n",
    "1. Did using a linear model produce good results for this dataset? Why or why not?\n",
    "\n",
    "The linear model produced good results, but they were not amazing or terrible.  The model may be more accurate if the R2 score was closer to 1. But above 0.6 is not bad. For MSE, the validation accuracy being lower than our training accuracy is good as that means we are not overfitting our training data."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ca0ff2f",
   "metadata": {},
   "source": [
    "### Process Description (4 marks)\n",
    "Please describe the process you used to create your code. Cite any websites or generative AI tools used. You can use the following questions as guidance:\n",
    "1. Where did you source your code?\n",
    "1. In what order did you complete the steps?\n",
    "1. If you used generative AI, what prompts did you use? Did you need to modify the code at all? Why or why not?\n",
    "1. Did you have any challenges? If yes, what were they? If not, what helped you to be successful?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dfdb0880",
   "metadata": {},
   "source": [
    "*DESCRIBE YOUR PROCESS HERE*\n",
    "\n",
    "For part 2 of the assignment. I referred back to part 1 of the assignment for certain parts such as assigning X and y from the yellowbrick data set.  I also referred back to the Linear Regression notebook that was covered in class. However, in order to use the built-in sklearn functions (MSE, and R2_score) I used the code from the sklearn website for both MSE and R2_score. (cited below). I did not use any generative AI for this section. The hardest part was figuring out how to use the MSE and R2_score functions and making sense of the results.\n",
    "\n",
    "sklearn.metrics.mean_squared_error, https://scikit-learn.org/stable/modules/generated/sklearn.metrics.mean_squared_error.html\n",
    "\n",
    "sklearn.metrics.r2_score, https://scikit-learn.org/stable/modules/generated/sklearn.metrics.r2_score.html\n",
    "\n",
    "Mean Square Error & R2 Score Clearly Explained, https://www.bmc.com/blogs/mean-squared-error-r2-and-variance-in-regression-analysis/#:~:text=There%20is%20no%20correct%20value,means%20the%20model%20is%20perfect.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e72ac3eb",
   "metadata": {},
   "source": [
    "## Part 3: Observations/Interpretation (3 marks)\n",
    "\n",
    "Describe any pattern you see in the results. Relate your findings to what we discussed during lectures. Include data to justify your findings.\n",
    "\n",
    "\n",
    "*ADD YOUR FINDINGS HERE*\n",
    "\n",
    "From the results, we can see that for the MSE score, our validation model is a bit more accurate compared to our training model. This may be due to some more outliers in the training set.  Since our R2 scores are similar for training and validation, we can say that our model has low variance.  Since our R2 values are around 0.6, we can also say that the model has moderate bias. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40b84eed",
   "metadata": {},
   "source": [
    "## Part 4: Reflection (2 marks)\n",
    "Include a sentence or two about:\n",
    "- what you liked or disliked,\n",
    "- found interesting, confusing, challangeing, motivating\n",
    "while working on this assignment.\n",
    "\n",
    "\n",
    "*ADD YOUR THOUGHTS HERE*\n",
    "\n",
    "I liked that this assignment built on things that we covered in class. It made it easy to follow along for the steps, but worked well as a review for the things we learnt about in class.  The questions at the end of each part made this assignment more interesting, as we had to explain the answers we got to, not just give our code."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db951b3a",
   "metadata": {},
   "source": [
    "## Part 5: Bonus Question (4 marks)\n",
    "\n",
    "Repeat Part 2 with Ridge and Lasso regression to see if you can improve the accuracy results. Which method and what value of alpha gave you the best R^2 score? Is this score \"good enough\"? Explain why or why not.\n",
    "\n",
    "**Remember**: Only test values of alpha from 0.001 to 100 along the logorithmic scale."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 336,
   "id": "47623d44",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     Training accuracy  Validation accuracy\n",
      "MSE         111.358439            95.904035\n",
      "R2            0.610823             0.623415\n"
     ]
    }
   ],
   "source": [
    "# TO DO: ADD YOUR CODE HERE\n",
    "\n",
    "#Ridge regression\n",
    "from sklearn.linear_model import Ridge \n",
    "ridge = Ridge().fit(X_train, y_train) \n",
    "y_train_pred = ridge.predict(X_train)\n",
    "y_val_pred = ridge.predict(X_val)\n",
    "\n",
    "#Mean squared error\n",
    "mse_train = mean_squared_error(y_train, y_train_pred)\n",
    "mse_val = mean_squared_error(y_val_pred,y_val)\n",
    "\n",
    "#R2_score\n",
    "r2_train = r2_score(y_train, y_train_pred)\n",
    "r2_val = r2_score(y_val, y_val_pred)\n",
    "\n",
    "ridge_results = pd.DataFrame(columns= [\"Training accuracy\", \"Validation accuracy\"])\n",
    "ridge_results.loc[0] = mse_train, mse_val\n",
    "ridge_results.loc[1] = r2_train, r2_val\n",
    "ridge_results.index = ['MSE', 'R2']\n",
    "print(ridge_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 337,
   "id": "39db7951",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     Training accuracy  Validation accuracy\n",
      "MSE         111.419648            95.584678\n",
      "R2            0.610609             0.624669\n"
     ]
    }
   ],
   "source": [
    "#Lasso regression\n",
    "from sklearn.linear_model import Lasso\n",
    "lasso = Lasso().fit(X_train, y_train)\n",
    "y_train_pred = lasso.predict(X_train)\n",
    "y_val_pred = lasso.predict(X_val)\n",
    "\n",
    "#Mean squared error\n",
    "mse_train = mean_squared_error(y_train, y_train_pred)\n",
    "mse_val = mean_squared_error(y_val_pred,y_val)\n",
    "\n",
    "#R2_score\n",
    "r2_train = r2_score(y_train, y_train_pred)\n",
    "r2_val = r2_score(y_val, y_val_pred)\n",
    "\n",
    "lasso_results = pd.DataFrame(columns= [\"Training accuracy\", \"Validation accuracy\"])\n",
    "lasso_results.loc[0] = mse_train, mse_val\n",
    "lasso_results.loc[1] = r2_train, r2_val\n",
    "lasso_results.index = ['MSE', 'R2']\n",
    "print(lasso_results)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "694ac12b",
   "metadata": {},
   "source": [
    "After running the ridge regression, and lasso regression. The accuracy results did not change very much, and changing the alphas did not affect my results very much. The R^2 score at 61% is probably not good enough, as you would typically want to see a higher number."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
